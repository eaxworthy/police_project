{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'converted_logs/Press-log-Sep-22nd-thru-28th-2021.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6632/2964322406.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0min_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0min_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#extract all lines, removing newlines characters and whitespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'converted_logs/Press-log-Sep-22nd-thru-28th-2021.txt'"
     ]
    }
   ],
   "source": [
    "#get name on input file\n",
    "input_folder = 'converted_logs/text_files/'\n",
    "in_file = input('Input file: ')\n",
    "in_file = input_folder + in_file\n",
    "#extract all lines, removing newlines characters and whitespace\n",
    "with open(in_file, 'r') as file:\n",
    "    lines = [line.strip() for line in file.readlines()]\n",
    "\n",
    "#all new entries start with a time in format hh:mm\n",
    "time_pattern = \"^([0-9]{2}:[0-9]{2})\"\n",
    "consolidated_entries = []\n",
    "entry = \"\"\n",
    "length_lines = len(lines)\n",
    "i = 0\n",
    "\n",
    "#loop through lines, appending all lines regarding one entry together\n",
    "#into a single string\n",
    "while i < length_lines:\n",
    "    #if line starts with a time, start a new entry\n",
    "    if re.match(time_pattern, lines[i]):        \n",
    "        entry = lines[i]\n",
    "        i+=1\n",
    "        while  i < length_lines and not re.match(time_pattern, lines[i]):\n",
    "            entry += lines[i]\n",
    "            i += 1            \n",
    "    else:\n",
    "        print('Error in input: non-standard line detected')\n",
    "        i += 1\n",
    "    #add complete entry to list\n",
    "    consolidated_entries.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define regex patterns\n",
    "location_pattern = \"\\s(on|at)\\s\"\n",
    "id_pattern = \"[0-9]{10}\"\n",
    "\n",
    "#give name of write file, or use default nameing scheme of the day of the first entry\n",
    "out_file = input(\"Enter name of output file, or type 'default' for default naming scheme(M_D_Y_entries.txt)\")\n",
    "if out_file.lower() == 'default':\n",
    "    #pull the id from the first entry, which contains date information\n",
    "    idx = re.search(id_pattern, consolidated_entries[0]).start()\n",
    "    datestring = consolidated_entries[0][idx:idx+10]\n",
    " \n",
    "    out_file = datestring[2:4]+'_'+datestring[4:6]+'_'+datestring[0:2]\n",
    "\n",
    "output_folder = 'converted_logs/csvs/'\n",
    "out_file=out_file+'.csv'\n",
    "\n",
    "#Write file headers\n",
    "with open(out_file, 'w') as file:\n",
    "    file.write(\"ID,time,category,location,sublocation,description,disposition\\n\")\n",
    "\n",
    "#Seperate each entry into field\n",
    "for entry in consolidated_entries:\n",
    "    #extract the time (given in military time, always the first 5 characters)\n",
    "    time = entry[0:5]\n",
    "    entry = entry[5:]\n",
    "    \n",
    "    #find the index of the 10 digit entry id\n",
    "    id_idx = re.search(id_pattern, entry).start()\n",
    "    #the category of entry is everything up until the id starts. Quotes\n",
    "    #are placed around the string to prevent issues in csv conversion.\n",
    "    category = '\\\"'+entry[:id_idx].strip()+'\\\"'\n",
    "    \n",
    "    #extract id #\n",
    "    entry_id = entry[id_idx:id_idx + 10]\n",
    "    #<TO DO>\n",
    "    #extract date information from id\n",
    "    \n",
    "    #All locations follow a pattern of <various string> [on|at] location, so\n",
    "    #the first match of on|at is followed by the location name\n",
    "    occurred_idx = re.search(location_pattern, entry).end()\n",
    "    entry = entry[occurred_idx:]\n",
    "    \n",
    "    #the description will follow the '.' ending the location\n",
    "    description_idx = entry.find('.')+1\n",
    "    \n",
    "    #everything up to the period is grabbed, and unneeded information like town\n",
    "    #name (all entries are in Fairfax) or common puncutation quirks are removed\n",
    "    #or standardized. Remaining location should be a street.\n",
    "    location = entry[0:description_idx].replace('Fairfax', '').replace(', .', '').replace(' ()', '').replace('.', '').replace(', ', '-').strip()\n",
    "    \n",
    "    #If the word 'on' remains in the location, that means an area within the \n",
    "    #main location is specified. Otherwise, N/A is used as a filler\n",
    "    if location.find(' on ') > 1:\n",
    "        idx = location.find(' on ')\n",
    "        sub_location = '\\\"'+location[0:idx]+'\\\"'\n",
    "        location = location[idx+4:]\n",
    "    else:\n",
    "        sub_location = 'N/A'\n",
    "    location = '\\\"'+location+'\\\"'\n",
    "    entry = entry[description_idx:]\n",
    "    \n",
    "    #The entry description is everything up until the word 'Disposition'. Some entries\n",
    "    #do not have additional desciptive text.\n",
    "    disposition_idx = entry.find('Disposition:')\n",
    "    \n",
    "    #Formatting quirks removed.\n",
    "    description = '\\\"'+entry[:disposition_idx].lstrip(\". \").replace(\" .\", '').replace('..', '.').strip()+'\\\"'\n",
    "    if description == '':\n",
    "        description = 'NA'\n",
    "    \n",
    "    #Fomatting quirks removed, and a common typo fixed.\n",
    "    disposition = '\\\"'+entry[disposition_idx:].replace('Disposition:', '').strip().replace('ServiceProvided.', 'Service Provided.')+'\\\"'\n",
    "\n",
    "    #entries saved to file specified by outfile\n",
    "    with open(out_file,'a') as file:\n",
    "        file.write(entry_id + ',' + time+ ',' +category+ ',' +location+ ',' + sub_location + ',' +description+ ',' +disposition+'\\n')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
